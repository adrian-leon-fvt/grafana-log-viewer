{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39cc37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-14 17:31:25,373] send_d65_data.py:609  ðŸ“ Reading CANCloud files from D:\\d65files ...\n",
      "[2025-11-14 17:31:25,948] send_d65_data.py:617  âœ”ï¸  [CANCloud] Found 271 files in 0.574s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to process: 130\n"
     ]
    }
   ],
   "source": [
    "from asammdf import MDF\n",
    "from datetime import datetime, timedelta\n",
    "from zoneinfo import ZoneInfo\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "sys.path.append(str(Path(\"D:/utils/grafana-log-viewer\").resolve()))\n",
    "\n",
    "from decoder.D65.send_d65_data import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "start_date= datetime(2025, 8, 1, tzinfo=ZoneInfo(\"America/Vancouver\"))\n",
    "end_date = start_date + timedelta(days=30)\n",
    "files: list[CSVContent] = [f for f in get_all_d65_cancloud_files(start=start_date, end=end_date) if f[1] == 'Lower']\n",
    "\n",
    "print(f\"Total files to process: {len(files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c24c100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-14 17:31:36,428] 2209917334.py:35 Progress: 2/130 files processed.\n",
      "[2025-11-14 17:31:43,250] 2209917334.py:35 Progress: 6/130 files processed.\n",
      "[2025-11-14 17:31:52,925] 2209917334.py:35 Progress: 8/130 files processed.\n",
      "[2025-11-14 17:31:59,579] 2209917334.py:35 Progress: 9/130 files processed.\n",
      "[2025-11-14 17:32:05,167] 2209917334.py:35 Progress: 11/130 files processed.\n",
      "[2025-11-14 17:32:10,903] 2209917334.py:35 Progress: 16/130 files processed.\n",
      "[2025-11-14 17:32:18,935] 2209917334.py:35 Progress: 20/130 files processed.\n",
      "[2025-11-14 17:32:25,254] 2209917334.py:35 Progress: 22/130 files processed.\n",
      "[2025-11-14 17:32:33,251] 2209917334.py:35 Progress: 26/130 files processed.\n",
      "[2025-11-14 17:32:38,985] 2209917334.py:35 Progress: 30/130 files processed.\n",
      "[2025-11-14 17:32:44,249] 2209917334.py:35 Progress: 34/130 files processed.\n",
      "[2025-11-14 17:32:49,370] 2209917334.py:35 Progress: 39/130 files processed.\n",
      "[2025-11-14 17:32:58,719] 2209917334.py:35 Progress: 44/130 files processed.\n",
      "[2025-11-14 17:33:04,200] 2209917334.py:35 Progress: 48/130 files processed.\n",
      "[2025-11-14 17:33:09,229] 2209917334.py:35 Progress: 53/130 files processed.\n",
      "[2025-11-14 17:33:14,789] 2209917334.py:35 Progress: 56/130 files processed.\n",
      "[2025-11-14 17:33:21,556] 2209917334.py:35 Progress: 62/130 files processed.\n",
      "[2025-11-14 17:33:27,299] 2209917334.py:35 Progress: 65/130 files processed.\n",
      "[2025-11-14 17:33:33,970] 2209917334.py:35 Progress: 69/130 files processed.\n",
      "[2025-11-14 17:33:39,796] 2209917334.py:35 Progress: 71/130 files processed.\n",
      "[2025-11-14 17:33:44,938] 2209917334.py:35 Progress: 75/130 files processed.\n",
      "[2025-11-14 17:33:53,931] 2209917334.py:35 Progress: 76/130 files processed.\n",
      "[2025-11-14 17:33:59,889] 2209917334.py:35 Progress: 82/130 files processed.\n",
      "[2025-11-14 17:34:07,127] 2209917334.py:35 Progress: 85/130 files processed.\n",
      "[2025-11-14 17:34:12,688] 2209917334.py:35 Progress: 87/130 files processed.\n",
      "[2025-11-14 17:34:18,629] 2209917334.py:35 Progress: 90/130 files processed.\n",
      "[2025-11-14 17:34:35,117] 2209917334.py:35 Progress: 91/130 files processed.\n",
      "[2025-11-14 17:34:41,611] 2209917334.py:35 Progress: 94/130 files processed.\n",
      "[2025-11-14 17:34:46,705] 2209917334.py:35 Progress: 97/130 files processed.\n",
      "[2025-11-14 17:34:58,672] 2209917334.py:35 Progress: 101/130 files processed.\n",
      "[2025-11-14 17:35:08,224] 2209917334.py:35 Progress: 105/130 files processed.\n",
      "[2025-11-14 17:35:13,650] 2209917334.py:35 Progress: 109/130 files processed.\n",
      "[2025-11-14 17:35:20,408] 2209917334.py:35 Progress: 115/130 files processed.\n",
      "[2025-11-14 17:35:29,796] 2209917334.py:35 Progress: 116/130 files processed.\n",
      "[2025-11-14 17:35:36,910] 2209917334.py:35 Progress: 118/130 files processed.\n",
      "[2025-11-14 17:35:47,318] 2209917334.py:35 Progress: 120/130 files processed.\n",
      "[2025-11-14 17:35:58,833] 2209917334.py:35 Progress: 124/130 files processed.\n",
      "[2025-11-14 17:36:06,560] 2209917334.py:35 Progress: 128/130 files processed.\n",
      "[2025-11-14 17:36:07,692] 2209917334.py:40 Total files containing 0x0000FF18: 0\n"
     ]
    }
   ],
   "source": [
    "def process(f: Path, pgn: int) -> tuple[bool, Path]:\n",
    "    single_mdf = MDF(f, process_bus_logging=False)\n",
    "    df = single_mdf.to_dataframe()\n",
    "    df.columns = [col.replace(\"CAN_DataFrame.\", \"\") for col in df.columns]\n",
    "    def check_column(col_name: str) -> bool:\n",
    "        if col_name not in df.columns:\n",
    "            return False\n",
    "\n",
    "        df[col_name + \"hex\"] = df[col_name].apply(lambda x: hex(x))\n",
    "        ids = df[col_name + \"hex\"].unique().tolist()\n",
    "        ids.sort()\n",
    "        return (pgn << 8) in [int(_id,16) & 0x00FFFF00 for _id in ids]\n",
    "    \n",
    "    for col in [\"ID\"] + [c for c in df.columns if c.startswith(\"ID_\")]:\n",
    "        if check_column(col):\n",
    "            return (True, f)\n",
    "\n",
    "    return (False, f)\n",
    "\n",
    "test_pgn = 0xFF18\n",
    "ts = time.time()\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(process, f, test_pgn) for f, _, _ in files]\n",
    "    _found_list = []\n",
    "    last_list_size = 0\n",
    "    for i, future in enumerate(as_completed(futures)):\n",
    "        found, _file = future.result()\n",
    "        new_ts = time.time()\n",
    "        if new_ts - ts > 5:\n",
    "            ts = new_ts\n",
    "            if last_list_size != len(_found_list):\n",
    "                last_list_size = len(_found_list)\n",
    "                logging.info(f\"Progress: {i}/{len(files)} files processed, {_found_list} found so far.\")\n",
    "            else:\n",
    "                logging.info(f\"Progress: {i}/{len(files)} files processed.\")\n",
    "        if found:\n",
    "            logging.info(f\"[{i:03d}] âœ… Found in {shortpath(_file)}\")\n",
    "            _found_list.append(_file)\n",
    "\n",
    "logging.info(f\"Total files containing 0x{test_pgn:08X}: {len(_found_list)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
